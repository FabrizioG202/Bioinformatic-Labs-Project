{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "MSA_FILEPATH = \"./data/alignment/intersection.sto\"\n",
    "CODES_PATH = \"./data/codes/intersection.txt\"\n",
    "EVALUES_SAVE_PATH = \"./data/evalues/intersection.tsv\"\n",
    "\n",
    "MSA_NAME = b\"KUNITZ\"\n",
    "\n",
    "# Controls\n",
    "NEGATIVE_CONTROL_PATH = \"./data/test/negative.fasta\"\n",
    "POSITIVE_CONTROL_PATH = \"./data/test/positive.fasta\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyhmmer\n",
    "\n",
    "# Build the HMM\n",
    "alphabet = pyhmmer.easel.Alphabet.amino()\n",
    "builder = pyhmmer.plan7.Builder(alphabet,)\n",
    "background = pyhmmer.plan7.Background(alphabet)\n",
    "\n",
    "# read the MSA\n",
    "with pyhmmer.easel.MSAFile(MSA_FILEPATH, digital=True, alphabet=alphabet) as msa_file:\n",
    "    msa = msa_file.read()\n",
    "    msa.name = MSA_NAME\n",
    "\n",
    "hmm, _, _ =  builder.build_msa(msa, background)\n",
    "\n",
    "# Load the HMM from a file called test.hmm  \n",
    "# with pyhmmer.plan7.HMMFile(\"./test.hmm\") as hmm_file:\n",
    "#     hmm = hmm_file.read()\n",
    "\n",
    "# save the HMM to a file called models/union.hmm\n",
    "with open(\"./models/foldseek.hmm\", \"wb\") as hmm_file:\n",
    "    hmm.write(hmm_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File ./data/test/negative.fasta already exists\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "112kiB [00:00, 243kiB/s]  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'./data/test/positive.fasta'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import urllib.parse\n",
    "import tqdm \n",
    "import os\n",
    "\n",
    "# Parse the codes to exclude from the search in the positive set\n",
    "# Split at , and at _ to get the codes\n",
    "with open(CODES_PATH, \"r\") as codes_file:\n",
    "    codes = codes_file.read().split(\",\")\n",
    "    \n",
    "    # Remove empty lines\n",
    "    codes = [code for code in codes if code != \"\"]\n",
    "    \n",
    "    # Remove the _ and everything after it\n",
    "    codes = [code.split(\"_\")[0] for code in codes]\n",
    "\n",
    "# Downloads the given uniprot query as a fasta file\n",
    "# and returns the path to the file\n",
    "def download_uniprot_fasta(query: str, output_path: str, eclude_codes :list[str] = None, overwrite  : bool = False) -> str:\n",
    "    \"\"\"Download the given uniprot query as a fasta file\"\"\"\n",
    "    # Set the URL for the Data API\n",
    "    # first we format the query so that it can be used in the url\n",
    "    \n",
    "    # add the codes to exclude (if any)\n",
    "    # the code works like this: NOT (xref:pdb-3tgi) NOT (xref:pdb-3tgi) ...\n",
    "    if eclude_codes != None:\n",
    "        query += \" AND \"\n",
    "        query += \" \".join([f\"NOT (xref:pdb-{code})\" for code in eclude_codes])        \n",
    "    query = urllib.parse.quote(query)\n",
    "    url = f'https://rest.uniprot.org/uniprotkb/stream?format=fasta&query={query}'\n",
    "    \n",
    "    # print(url)\n",
    "    \n",
    "    # download and show progress\n",
    "    response = requests.get(url, stream=True)\n",
    "    total_size_in_bytes= int(response.headers.get('content-length', 0))\n",
    "    \n",
    "    # Check if the request was successful\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Failed to download {query}\")\n",
    "        return None\n",
    "    \n",
    "    # If the file already exists and overwrite is false, return the path\n",
    "    if not overwrite and os.path.exists(output_path):\n",
    "        print(f\"File {output_path} already exists\")\n",
    "        return output_path\n",
    "    \n",
    "    # download the file displaying the progress in megabytes\n",
    "    block_size = 1024 #1 Kibibyte\n",
    "    with open(output_path, 'wb') as file, tqdm.tqdm(total=total_size_in_bytes, unit='iB', unit_scale=True) as progress_bar:\n",
    "        for data in response.iter_content(block_size):\n",
    "            progress_bar.update(len(data))\n",
    "            file.write(data)        \n",
    "\n",
    "    return output_path\n",
    "\n",
    "NEGATIVE_CONTROL_QUERY = \"NOT (xref:pfam-PF00014) AND (length:[58 TO *]) AND (reviewed:true)\"\n",
    "POSITIVE_CONTROL_QUERY = \"xref:pfam-PF00014 AND (length:[58 TO *]) AND (reviewed:true)\"\n",
    "\n",
    "# Download the negative control\n",
    "download_uniprot_fasta(NEGATIVE_CONTROL_QUERY, NEGATIVE_CONTROL_PATH)\n",
    "\n",
    "# # Download the positive control\n",
    "download_uniprot_fasta(POSITIVE_CONTROL_QUERY, POSITIVE_CONTROL_PATH, overwrite  = True) # Uncomment this to download all the positives\n",
    "# download_uniprot_fasta(POSITIVE_CONTROL_QUERY, POSITIVE_CONTROL_PATH, codes, overwrite  = True) # Uncomment this to download all the positives minus the ones in the codes file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "# Computes the MCC from the TP, FP, TN, FN\n",
    "def compute_mcc(tp, fp, tn, fn):\n",
    "    \n",
    "    numerator = tp * tn - fp * fn\n",
    "    denominator = math.sqrt((tp + fp) * (tp + fn) * (tn + fp) * (tn + fn))\n",
    "    \n",
    "    # if the denominator is 0 return 0 (invalid value)\n",
    "    if denominator == 0:\n",
    "        return 0\n",
    "    \n",
    "    \n",
    "    return numerator / denominator\n",
    "\n",
    "# Computes the accuracy from the TP, FP, TN, FN\n",
    "def compute_accuracy(tp, fp, tn, fn):\n",
    "    return (tp + tn) / (tp + fp + tn + fn)\n",
    "\n",
    "# Computes the precision and recall from the TP, FP, TN, FN\n",
    "# also returns the f1 score\n",
    "def compute_precision_and_recall(tp, fp, tn, fn):\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    \n",
    "    return precision, recall, 2 * precision * recall / (precision + recall)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appling the HMM to a sequence database and CVing the E-Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read the files\n",
      "Testing evalue: 1e-05\n",
      "TP: 345, FP: 0, TN: 553177, FN: 2\n"
     ]
    }
   ],
   "source": [
    "# The evalues tested during the cross validation\n",
    "# from 1e10-3 to 1e-12\n",
    "TESTED_EVALUES = [10 ** -i for i in range(2, 20)] # Uncomment this to test all the evalues\n",
    "# TESTED_EVALUES = [10 ** -5] # Uncomment this to test only one evalue\n",
    "\n",
    "# the results of the cross validation\n",
    "# saves the evalue, accuracy, precision, recall, f1, tp, fp, tn, fn\n",
    "cv_results = []\n",
    "\n",
    "# open both files (negative and positive) and count the amount of sequences\n",
    "# this is done to compute the true negatives and true positives\n",
    "positive_file = pyhmmer.easel.SequenceFile(POSITIVE_CONTROL_PATH, digital=True, alphabet=alphabet)\n",
    "negative_file = pyhmmer.easel.SequenceFile(NEGATIVE_CONTROL_PATH, digital=True, alphabet=alphabet)\n",
    "\n",
    "# count the amount of sequences in the files (they are the same, independent of the evalue)\n",
    "positive_ = len(positive_file.read_block())\n",
    "negative_ = len(negative_file.read_block())\n",
    "\n",
    "# print the fact that the files were read\n",
    "print(\"Read the files\")\n",
    "\n",
    "# iterate over the evalues\n",
    "for evalue in TESTED_EVALUES:\n",
    "\n",
    "    # rewind the files to the beginning\n",
    "    positive_file.rewind()\n",
    "    negative_file.rewind()\n",
    "\n",
    "    # print the evalue being tested\n",
    "    print(f\"Testing evalue: {evalue}\")\n",
    "\n",
    "    # Create the pipeline\n",
    "    pipeline = pyhmmer.plan7.Pipeline(alphabet, background=background, E=evalue)\n",
    "\n",
    "    # Search the negative control\n",
    "    negative_hits = pipeline.search_hmm(hmm, negative_file, )\n",
    "        \n",
    "    # Search the positive control\n",
    "    positive_hits = pipeline.search_hmm(hmm, positive_file, )\n",
    "        \n",
    "    # Compute a confusion matrix    \n",
    "    true_positives = len(positive_hits)\n",
    "    false_positives = len(negative_hits)\n",
    "    true_negatives = negative_ - false_positives\n",
    "    false_negatives = positive_ - true_positives\n",
    "    \n",
    "    # print all the metrics\n",
    "    print(f\"TP: {true_positives}, FP: {false_positives}, TN: {true_negatives}, FN: {false_negatives}\")\n",
    "\n",
    "    # Compute the metrics and save them\n",
    "    accuracy = compute_accuracy(true_positives, false_positives, true_negatives, false_negatives)\n",
    "    precision, recall, f1 = compute_precision_and_recall(true_positives, false_positives, true_negatives, false_negatives)\n",
    "    mcc = compute_mcc(true_positives, false_positives, true_negatives, false_negatives)\n",
    "    cv_results.append((evalue, f1, accuracy, precision, recall, mcc, true_positives, false_positives, true_negatives, false_negatives))\n",
    "    \n",
    "# close the files\n",
    "positive_file.close()\n",
    "negative_file.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identifying the Wrongly classified Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"b'sp|O62247|BLI5_CAEEL'\", \"b'sp|D3GGZ8|BLI5_HAECO'\"]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the pipeline\n",
    "pipeline = pyhmmer.plan7.Pipeline(alphabet, background=background, E=10**-5)\n",
    "\n",
    "# Search the positive control\n",
    "positive_file = pyhmmer.easel.SequenceFile(POSITIVE_CONTROL_PATH, digital=True, alphabet=alphabet)\n",
    "\n",
    "# Get all the positive names\n",
    "all_positive_names = [str(seq.name) for seq in positive_file.read_block()]\n",
    "\n",
    "# Search the positive control\n",
    "positive_file.rewind()\n",
    "positive_hits = pipeline.search_hmm(hmm, positive_file, )\n",
    "positive_file.close()\n",
    "\n",
    "# Get the names of the positive hits\n",
    "positive_hits_names = [str(hit.name) for hit in positive_hits]\n",
    "\n",
    "# Get the names of the wrongly classified sequences\n",
    "wrongly_classified = [name for name in all_positive_names if name not in positive_hits_names]\n",
    "wrongly_classified"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving E-Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save a TSV with the results\n",
    "with open(EVALUES_SAVE_PATH, \"w\") as file:\n",
    "    file.write(\"evalue\\tf1\\taccuracy\\tprecision\\trecall\\tmcc\\tTP\\tFP\\tTN\\tFN\\n\")\n",
    "    for result in cv_results:\n",
    "        file.write(\"\\t\".join(map(str, result)) + \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
