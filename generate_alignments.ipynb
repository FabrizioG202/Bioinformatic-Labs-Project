{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing stuff\n",
    "from utils import get_pdb_resolution_list, get_sequences_from_file, download_pdb_sequences\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining constants\n",
    "# We're limiting the resolution [Combined Resolution] to 3.0 as higher (lower quality) resolutions are not reliable\n",
    "MAX_RESOLUTION = 3.0\n",
    "MIN_Z_SCORE = 2.0 # Suggested on the DALI website\n",
    "MAX_RMSD = 2.0\n",
    "MAX_EVALUE_FOLDSEEK = 0.001 # suggested on the foldseek website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common names for metrics\n",
    "TARGET_COLUMN = 'target'\n",
    "TARGET_PDB_COLUMN = 'target_pdb'\n",
    "QUERY_COLUMN = 'query'\n",
    "Z_SCORE_COLUMN = 'z-score'\n",
    "RMSD_COLUMN = 'rmsd'\n",
    "SEQUENCE_COLUMN = 'sequence'\n",
    "RESOLUTION_COLUMN = 'resolution'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the path to the incoming dump files\n",
    "PDBE_SEARCH_RESULTS_PATH =\"./data/search_results/pdbe.txt\"\n",
    "DALI_SEARCH_RESULTS_PATH = \"./data/search_results/dali.txt\"\n",
    "FOLDSEEK_SEARCH_RESULTS_PATH = \"./data/search_results/foldseek.tsv\"\n",
    "\n",
    "# The path to the output (codes) files.\n",
    "PDBE_CODES_PATH = \"./data/codes/pdbe.txt\"   \n",
    "DALI_CODES_PATH = \"./data/codes/dali.txt\"\n",
    "FOLDSEEK_CODES_PATH = \"./data/codes/foldseek.txt\"\n",
    "INTERSECTION_CODES_PATH = \"./data/codes/intersection.txt\"\n",
    "\n",
    "# The path to the output (sequences pre-clustering) files.\n",
    "PDBE_PRECLUSTERING_SEQUENCES_PATH = \"./data/sequences/preclustering-pdbe.txt\"\n",
    "DALI_PRECLUSTERING_SEQUENCES_PATH = \"./data/sequences/preclustering-dali.txt\"\n",
    "FOLDSEEK_PRECLUSTERING_SEQUENCES_PATH = \"./data/sequences/preclustering-foldseek.txt\"\n",
    "INTERSECTION_PRECLUSTERING_SEQUENCES_PATH = \"./data/sequences/preclustering-intersection.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we now add a sequences column to the dataframe\n",
    "# we do so by getting the sequences from the PDB SEQRES file\n",
    "SEQ_RES_PATH = download_pdb_sequences()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Common Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filters a datagrame\n",
    "# it filters by resolution, z-score, and rmsd and evalue\n",
    "# for each of these filters it first checks if the column exists\n",
    "# since for example foldseek doesn't have a z-score column\n",
    "# it keeps track of which filters were applied\n",
    "# and prints out a message with the filters that were applied\n",
    "def filter_dataframe(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Filter a dataframe by resolution, z-score, and rmsd and evalue\"\"\"\n",
    "    # keep track of which filters were applied\n",
    "    filters = []\n",
    "    len_before = len(df)\n",
    "    \n",
    "    # filter by resolution\n",
    "    if RESOLUTION_COLUMN in df.columns:\n",
    "        df = df[df[RESOLUTION_COLUMN] <= MAX_RESOLUTION]\n",
    "        filters.append(f\"resolution <= {MAX_RESOLUTION}\")\n",
    "    \n",
    "    # filter by z-score\n",
    "    if Z_SCORE_COLUMN in df.columns:\n",
    "        df = df[df[Z_SCORE_COLUMN] >= MIN_Z_SCORE]\n",
    "        filters.append(f\"z-score >= {MIN_Z_SCORE}\")\n",
    "    \n",
    "    # filter by rmsd\n",
    "    if RMSD_COLUMN in df.columns:\n",
    "        df = df[df[RMSD_COLUMN] <= MAX_RMSD]\n",
    "        filters.append(f\"rmsd <= {MAX_RMSD}\")\n",
    "    \n",
    "    # filter by evalue\n",
    "    if 'evalue' in df.columns:\n",
    "        df = df[df['evalue'] <= MAX_EVALUE_FOLDSEEK]\n",
    "        filters.append(f\"evalue <= {MAX_EVALUE_FOLDSEEK}\")\n",
    "    \n",
    "    # print out the filters that were applied\n",
    "    print(f\"Applied filters: {', '.join(filters)} ({len_before - len(df)} rows removed)\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# removes duplicate rows from a dataframe (rows with the same target_pdb and sequence)\n",
    "# also logs the number of duplicate rows that were removed\n",
    "def remove_duplicate_rows(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Remove duplicate rows from a dataframe\"\"\"\n",
    "    # get the number of rows before removing duplicates\n",
    "    num_rows_before = len(df)\n",
    "    \n",
    "    # remove duplicate rows\n",
    "    df = df.drop_duplicates(subset=[TARGET_PDB_COLUMN, SEQUENCE_COLUMN])\n",
    "    \n",
    "    # get the number of rows after removing duplicates\n",
    "    num_rows_after = len(df)\n",
    "    \n",
    "    # log the number of rows removed\n",
    "    print(f\"Removed {num_rows_before - num_rows_after} duplicate rows\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Adds a column to the dataframe with the resolution of the PDB ID\n",
    "# The resolution is obtained using the get_pdb_resolution_list function\n",
    "async def add_resolution_column(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Add a column to the dataframe with the resolution of the PDB ID\"\"\"\n",
    "    # get the resolutions\n",
    "    resolutions : dict[str, float] = await get_pdb_resolution_list(set(df[TARGET_PDB_COLUMN].unique()))\n",
    "    \n",
    "    # add the resolution column\n",
    "    df[RESOLUTION_COLUMN] = df[TARGET_PDB_COLUMN].map(lambda x: resolutions[x])\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "# adds a column to the dataframe with the sequence of the PDB ID\n",
    "# The sequence is obtained using the get_sequences_from_file function\n",
    "def add_sequence_column(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Add a column to the dataframe with the sequence of the PDB ID\"\"\"\n",
    "    # get the sequences\n",
    "    sequences : dict[str, str] = get_sequences_from_file((df[TARGET_COLUMN].values), res_seq_path=SEQ_RES_PATH)\n",
    "    \n",
    "    # add the sequence column\n",
    "    df[SEQUENCE_COLUMN] = df[TARGET_COLUMN].map(lambda x: sequences[x])\n",
    "    \n",
    "    return df\n",
    "\n",
    "# A utility function which groups all the above functions\n",
    "async def process_dataframe(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Process a dataframe by filtering and removing duplicates\"\"\"\n",
    "    df = await add_resolution_column(df)\n",
    "    \n",
    "    # If the sequence column doesn't exist, add it\n",
    "    if SEQUENCE_COLUMN not in df.columns:\n",
    "        df = add_sequence_column(df)\n",
    "    else:\n",
    "        print(\"Sequence column already exists\")\n",
    "\n",
    "    df = remove_duplicate_rows(df)\n",
    "    df = filter_dataframe(df)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writes a fasta file with the sequences of the filtered dataframe\n",
    "# To the file specified by the path\n",
    "def write_fasta(df: pd.DataFrame, path: str) -> None:\n",
    "    \"\"\"Writes a fasta file with the sequences of the filtered dataframe\"\"\"\n",
    "    \n",
    "    with open(path, \"w\") as f:\n",
    "        for index, row in df.iterrows():\n",
    "            f.write(f\">{row[TARGET_COLUMN]}\\n{row[SEQUENCE_COLUMN]}\\n\\n\")\n",
    "        \n",
    "# writes a file with all the pdb codes and chains of the filtered dataframe to the path\n",
    "# with the provided separator\n",
    "def write_pdb_codes(df: pd.DataFrame, path: str, sep = \",\"):\n",
    "    \"\"\"Writes a file with all the pdb codes and chains of the filtered dataframe to the path\"\"\"\n",
    "    with open(path, \"w\") as f:\n",
    "        f.write(sep.join(df[TARGET_COLUMN].unique()))\n",
    "        \n",
    "# Reads a file with the pdb codes and chains and returns a list of them\n",
    "def read_pdb_codes(path: str, sep = \",\") -> list[str]:\n",
    "    \"\"\"Reads a file with the pdb codes and chains and returns a list of them\"\"\"\n",
    "    with open(path, \"r\") as f:\n",
    "        return f.read().split(sep)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing all the file types\n",
    "For each of the methods below, the database will follow the conventions for the column names"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing the PDBe Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 0 duplicate rows\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q-score</th>\n",
       "      <th>P-score</th>\n",
       "      <th>z-score</th>\n",
       "      <th>rmsd</th>\n",
       "      <th>Nalgn</th>\n",
       "      <th>Nsse</th>\n",
       "      <th>Ngaps</th>\n",
       "      <th>Seq-%</th>\n",
       "      <th>Nmd</th>\n",
       "      <th>Nres-Q</th>\n",
       "      <th>Nsse-Q</th>\n",
       "      <th>Nres-T</th>\n",
       "      <th>Nsse-T</th>\n",
       "      <th>query</th>\n",
       "      <th>target</th>\n",
       "      <th>target_pdb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>16.18</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.000</td>\n",
       "      <td>58</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "      <td>4</td>\n",
       "      <td>58</td>\n",
       "      <td>4</td>\n",
       "      <td>5pti_A</td>\n",
       "      <td>5pti_A</td>\n",
       "      <td>5pti</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.9990</td>\n",
       "      <td>14.33</td>\n",
       "      <td>11.20</td>\n",
       "      <td>0.093</td>\n",
       "      <td>58</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9828</td>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "      <td>4</td>\n",
       "      <td>58</td>\n",
       "      <td>4</td>\n",
       "      <td>5pti_A</td>\n",
       "      <td>9pti_A</td>\n",
       "      <td>9pti</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.9956</td>\n",
       "      <td>12.59</td>\n",
       "      <td>10.48</td>\n",
       "      <td>0.199</td>\n",
       "      <td>58</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9655</td>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "      <td>4</td>\n",
       "      <td>58</td>\n",
       "      <td>4</td>\n",
       "      <td>5pti_A</td>\n",
       "      <td>7pti_A</td>\n",
       "      <td>7pti</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.9590</td>\n",
       "      <td>12.25</td>\n",
       "      <td>10.33</td>\n",
       "      <td>0.248</td>\n",
       "      <td>56</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9821</td>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "      <td>4</td>\n",
       "      <td>56</td>\n",
       "      <td>4</td>\n",
       "      <td>5pti_A</td>\n",
       "      <td>1bpt_A</td>\n",
       "      <td>1bpt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.9297</td>\n",
       "      <td>12.12</td>\n",
       "      <td>10.27</td>\n",
       "      <td>0.592</td>\n",
       "      <td>57</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9825</td>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "      <td>4</td>\n",
       "      <td>58</td>\n",
       "      <td>4</td>\n",
       "      <td>5pti_A</td>\n",
       "      <td>1fan_A</td>\n",
       "      <td>1fan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Q-score  P-score  z-score   rmsd  Nalgn  Nsse  Ngaps   Seq-%  Nmd  Nres-Q  \\\n",
       "0   1.0000    16.18    11.93  0.000     58     4      0  1.0000    0      58   \n",
       "1   0.9990    14.33    11.20  0.093     58     4      0  0.9828    0      58   \n",
       "2   0.9956    12.59    10.48  0.199     58     4      0  0.9655    0      58   \n",
       "3   0.9590    12.25    10.33  0.248     56     4      0  0.9821    0      58   \n",
       "4   0.9297    12.12    10.27  0.592     57     4      0  0.9825    0      58   \n",
       "\n",
       "   Nsse-Q  Nres-T  Nsse-T   query  target target_pdb  \n",
       "0       4      58       4  5pti_A  5pti_A       5pti  \n",
       "1       4      58       4  5pti_A  9pti_A       9pti  \n",
       "2       4      58       4  5pti_A  7pti_A       7pti  \n",
       "3       4      56       4  5pti_A  1bpt_A       1bpt  \n",
       "4       4      58       4  5pti_A  1fan_A       1fan  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# open the file read it, remove any \"PDB \" in the file and open it as a fixed width file in pandas \n",
    "# PDBe results are partially a fixed-width file for the exception of the first row (header)\n",
    "# so, to open we first format the data.\n",
    "with open(PDBE_SEARCH_RESULTS_PATH, \"r\") as f:\n",
    "    # The PDB code is redundant as we performed a search only against the PDB database\n",
    "    # Moreover, spaces in the last two columns would cause problems when reading the file\n",
    "    data = f.read().replace(\"PDB \", \"\")\n",
    "    \n",
    "    # replace any amount of whitespaces (from 1 on) with a single tab\n",
    "    data = re.sub(r\"[ ]+\", \"\\t\", data)\n",
    "    \n",
    "    # remove tabs at the beginning of the line (if any)\n",
    "    data = re.sub(r\"^\\t\", \"\", data, flags=re.MULTILINE)\n",
    "\n",
    "    # read the data into a pandas dataframe as a TSV file\n",
    "    pdbe_results = pd.read_csv(StringIO(data), sep=\"\\t\")\n",
    "    \n",
    "    # we remove duplicate rows (based on the Target column (if any))\n",
    "    # and log how many rows were removed for debugging purposes\n",
    "    len_before = len(pdbe_results)\n",
    "    pdbe_results.drop_duplicates(subset=\"Target\", inplace=True)\n",
    "    print(f\"Removed {len_before - len(pdbe_results)} duplicate rows\")\n",
    "  \n",
    "    # replace : in the Query and Target columns with _ (since it's how foldseek names the files and how sequences with chains are named in the seqres file from PDB)\n",
    "    pdbe_results[\"Query\"] = pdbe_results[\"Query\"].str.replace(\":\", \"_\")\n",
    "    pdbe_results[\"Target\"] = pdbe_results[\"Target\"].str.replace(\":\", \"_\") \n",
    "    \n",
    "    # Rename the Target and Query columns to target and query respectively\n",
    "    pdbe_results.rename(columns={\n",
    "        \"Target\": TARGET_COLUMN, \n",
    "        \"Query\": QUERY_COLUMN ,\n",
    "        \"RMSD\": RMSD_COLUMN,\n",
    "        \"Z-score\": Z_SCORE_COLUMN\n",
    "    }, inplace=True)\n",
    "    \n",
    "    # Add a column called target_pdb which is the first 4 characters of the Target column\n",
    "    pdbe_results[\"target_pdb\"] = pdbe_results[\"target\"].str.split(\"_\").str[0]\n",
    "    \n",
    "    # drop the column called ##\n",
    "    pdbe_results.drop(\"##\", axis=1, inplace=True)\n",
    "\n",
    "# Print the first 5 rows of the dataframe\n",
    "pdbe_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 135 duplicate rows\n",
      "Applied filters: resolution <= 3.0, z-score >= 2.0, rmsd <= 2.0 (23 rows removed)\n"
     ]
    }
   ],
   "source": [
    "pdbe_results = await process_dataframe(pdbe_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_fasta(pdbe_results, PDBE_PRECLUSTERING_SEQUENCES_PATH)\n",
    "write_pdb_codes(pdbe_results, PDBE_CODES_PATH)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing Outputs from foldseek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence column already exists\n",
      "Removed 137 duplicate rows\n",
      "Applied filters: resolution <= 3.0, rmsd <= 2.0, evalue <= 0.001 (35 rows removed)\n"
     ]
    }
   ],
   "source": [
    "# Foldseek output is just a tsv, open it as a dataframe, just add a column called target_pdb to the dataframe\n",
    "foldseek_results = pd.read_csv(FOLDSEEK_SEARCH_RESULTS_PATH, sep=\"\\t\")\n",
    "\n",
    "# rename the tseq column to sequence and add a column called target_pdb to the dataframe\n",
    "foldseek_results.rename(columns={\"tseq\": SEQUENCE_COLUMN}, inplace=True)\n",
    "foldseek_results[TARGET_PDB_COLUMN] = foldseek_results[TARGET_COLUMN].str.split(\"_\").str[0]\n",
    "\n",
    "# Process the dataframe\n",
    "foldseek_results = await process_dataframe(foldseek_results)\n",
    "\n",
    "# Write the sequences to a fasta file\n",
    "write_fasta(foldseek_results, FOLDSEEK_PRECLUSTERING_SEQUENCES_PATH)\n",
    "write_pdb_codes(foldseek_results, FOLDSEEK_CODES_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>target</th>\n",
       "      <th>qstart</th>\n",
       "      <th>tstart</th>\n",
       "      <th>evalue</th>\n",
       "      <th>prob</th>\n",
       "      <th>rmsd</th>\n",
       "      <th>sequence</th>\n",
       "      <th>target_pdb</th>\n",
       "      <th>resolution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5pti.pdb</td>\n",
       "      <td>7pti_A</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.582000e-10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1990</td>\n",
       "      <td>RPDFCLEPPYTGPCKARIIRYFYNAKAGLAQTFVYGGCRAKRNNFK...</td>\n",
       "      <td>7pti</td>\n",
       "      <td>1.6000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5pti.pdb</td>\n",
       "      <td>1bti_A</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7.734000e-11</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9165</td>\n",
       "      <td>RPDFCLEPPYTGPCKARIIRYAYNAKAGLCQTFVYGGCRAKRNNFK...</td>\n",
       "      <td>1bti</td>\n",
       "      <td>2.2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5pti.pdb</td>\n",
       "      <td>1fan_A</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.483000e-10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0200</td>\n",
       "      <td>RPDFCLEPPYTGPCKARIIRYFYNAKAGLCQTFVYGGCRAKRNNAK...</td>\n",
       "      <td>1fan</td>\n",
       "      <td>2.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5pti.pdb</td>\n",
       "      <td>1t7c_D</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.483000e-10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.2830</td>\n",
       "      <td>RPDFCLEPPYTGPCEARIIRYFYNAKAGLCQTFVYGGCRAKRNNFK...</td>\n",
       "      <td>1t7c</td>\n",
       "      <td>1.8500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5pti.pdb</td>\n",
       "      <td>3p92_E</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.483000e-10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9127</td>\n",
       "      <td>RPDFCLEPPYTGPCRAGIIRYFYNAKAGLCQTFVYGGCRAKRNNFK...</td>\n",
       "      <td>3p92</td>\n",
       "      <td>1.5992</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      query  target  qstart  tstart        evalue  prob    rmsd  \\\n",
       "0  5pti.pdb  7pti_A       1       1  1.582000e-10   1.0  0.1990   \n",
       "1  5pti.pdb  1bti_A       1       1  7.734000e-11   1.0  0.9165   \n",
       "2  5pti.pdb  1fan_A       1       1  1.483000e-10   1.0  1.0200   \n",
       "3  5pti.pdb  1t7c_D       1       1  1.483000e-10   1.0  1.2830   \n",
       "4  5pti.pdb  3p92_E       1       1  1.483000e-10   1.0  0.9127   \n",
       "\n",
       "                                            sequence target_pdb  resolution  \n",
       "0  RPDFCLEPPYTGPCKARIIRYFYNAKAGLAQTFVYGGCRAKRNNFK...       7pti      1.6000  \n",
       "1  RPDFCLEPPYTGPCKARIIRYAYNAKAGLCQTFVYGGCRAKRNNFK...       1bti      2.2000  \n",
       "2  RPDFCLEPPYTGPCKARIIRYFYNAKAGLCQTFVYGGCRAKRNNAK...       1fan      2.0000  \n",
       "3  RPDFCLEPPYTGPCEARIIRYFYNAKAGLCQTFVYGGCRAKRNNFK...       1t7c      1.8500  \n",
       "4  RPDFCLEPPYTGPCRAGIIRYFYNAKAGLCQTFVYGGCRAKRNNFK...       3p92      1.5992  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foldseek_results.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing DALI output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>z-score</th>\n",
       "      <th>rmsd</th>\n",
       "      <th>lali</th>\n",
       "      <th>nres</th>\n",
       "      <th>%id</th>\n",
       "      <th>target_pdb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5pti_A</td>\n",
       "      <td>14.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58</td>\n",
       "      <td>58</td>\n",
       "      <td>100</td>\n",
       "      <td>5pti</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9pti_A</td>\n",
       "      <td>14.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>58</td>\n",
       "      <td>58</td>\n",
       "      <td>98</td>\n",
       "      <td>9pti</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7pti_A</td>\n",
       "      <td>13.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>58</td>\n",
       "      <td>58</td>\n",
       "      <td>97</td>\n",
       "      <td>7pti</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1g6x_A</td>\n",
       "      <td>13.3</td>\n",
       "      <td>1.1</td>\n",
       "      <td>58</td>\n",
       "      <td>58</td>\n",
       "      <td>93</td>\n",
       "      <td>1g6x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1bpi_A</td>\n",
       "      <td>13.3</td>\n",
       "      <td>1.2</td>\n",
       "      <td>58</td>\n",
       "      <td>58</td>\n",
       "      <td>100</td>\n",
       "      <td>1bpi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target  z-score  rmsd  lali  nres  %id target_pdb\n",
       "0  5pti_A     14.8   0.0    58    58  100       5pti\n",
       "1  9pti_A     14.3   0.1    58    58   98       9pti\n",
       "2  7pti_A     13.9   0.2    58    58   97       7pti\n",
       "3  1g6x_A     13.3   1.1    58    58   93       1g6x\n",
       "4  1bpi_A     13.3   1.2    58    58  100       1bpi"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DALI outputs are strangely formatted:\n",
    "# this is an example of a DALI output:\n",
    "# No:  Chain   Z    rmsd lali nres  %id PDB  Description\n",
    "#    1:  5pti-A 14.8  0.0   58    58  100   MOLECULE: TRYPSIN INHIBITOR;                                         \n",
    "#    2:  9pti-A 14.3  0.1   58    58   98   MOLECULE: BOVINE PANCREATIC TRYPSIN INHIBITOR;    \n",
    "\n",
    "# to start, we open the file and read it as a string\n",
    "with open(DALI_SEARCH_RESULTS_PATH, \"r\") as f:\n",
    "    data = f.read()\n",
    "    \n",
    "    # We remove from MOLECULE: to the end of the line (since we don't need the description)\n",
    "    data = re.sub(r\"MOLECULE:.*$\", \"\", data, flags=re.MULTILINE)\n",
    "    \n",
    "    # We remove the # at the beginning of any line\n",
    "    data = re.sub(r\"^#\", \"\", data, flags=re.MULTILINE)\n",
    "    \n",
    "    # We then replace any amount of whitespaces (from 1 on) with a single tab and remove any tabs at the beginning of the line (if any)\n",
    "    data = re.sub(r\"[ ]+\", \"\\t\", data)\n",
    "    data = re.sub(r\"^\\t\", \"\", data, flags=re.MULTILINE)\n",
    "    \n",
    "    # We then read the data into a pandas dataframe as a TSV file\n",
    "    dali_results = pd.read_csv(StringIO(data), sep=\"\\t\")\n",
    "    \n",
    "    # We now fix columns\n",
    "    # - remove the Description column and No:, PDB and Description columns\n",
    "    # - rename the Chain column to target\n",
    "    # - rename the Z column to Z-score\n",
    "    # - rename the rmsd column to RMSD\n",
    "    dali_results.drop([\"Description\", \"No:\", \"PDB\"], axis=1, inplace=True)\n",
    "    dali_results.rename(columns={\"Chain\": TARGET_COLUMN, \"Z\": Z_SCORE_COLUMN, \"rmsd\": RMSD_COLUMN}, inplace=True)\n",
    "    \n",
    "    # We then lastly format the target column to be in the form of PDB_CHAIN instead of PDB-CHAIN\n",
    "    dali_results[TARGET_COLUMN] = dali_results[TARGET_COLUMN].str.replace(\"-\", \"_\")\n",
    "    \n",
    "    # We then add a column called target_pdb which is the first 4 characters of the Target column\n",
    "    dali_results[\"target_pdb\"] = dali_results[TARGET_COLUMN].str.split(\"_\").str[0]\n",
    "    \n",
    "dali_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 142 duplicate rows\n",
      "Applied filters: resolution <= 3.0, z-score >= 2.0, rmsd <= 2.0 (37 rows removed)\n"
     ]
    }
   ],
   "source": [
    "# Process the dataframe\n",
    "dali_results = await process_dataframe(dali_results)\n",
    "\n",
    "# Write the sequences to a fasta file\n",
    "write_fasta(dali_results, DALI_PRECLUSTERING_SEQUENCES_PATH)\n",
    "write_pdb_codes(dali_results, DALI_CODES_PATH)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing the results of the three methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDBE and Foldseek intersection: 83\n",
      "PDBE and DALI intersection: 138\n",
      "Foldseek and DALI intersection: 77\n",
      "PDBE, Foldseek and DALI intersection: 68\n",
      "PDBE codes: 168\n",
      "Foldseek codes: 122\n",
      "DALI codes: 169\n"
     ]
    }
   ],
   "source": [
    "# We open and read the codes file as a string and compare intersections between the codes\n",
    "pdbe_codes = set(read_pdb_codes(PDBE_CODES_PATH))\n",
    "foldseek_codes = set(read_pdb_codes(FOLDSEEK_CODES_PATH))\n",
    "dali_codes = set(read_pdb_codes(DALI_CODES_PATH))\n",
    "\n",
    "# We then get the intersection between the codes\n",
    "print(\"PDBE and Foldseek intersection:\", len(pdbe_codes.intersection(foldseek_codes)))\n",
    "print(\"PDBE and DALI intersection:\", len(pdbe_codes.intersection(dali_codes)))\n",
    "print(\"Foldseek and DALI intersection:\", len(foldseek_codes.intersection(dali_codes)))\n",
    "print(\"PDBE, Foldseek and DALI intersection:\", len(pdbe_codes.intersection(foldseek_codes).intersection(dali_codes)))\n",
    "\n",
    "# Print the number of codes in each set (For reference)\n",
    "print(\"PDBE codes:\", len(pdbe_codes))\n",
    "print(\"Foldseek codes:\", len(foldseek_codes))\n",
    "print(\"DALI codes:\", len(dali_codes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We save a fasta with the names of the codes that are in all 3 datasets\n",
    "# to do so, we get the intersection between the codes and then write the fasta\n",
    "intersection = pdbe_codes.intersection(foldseek_codes).intersection(dali_codes)\n",
    "\n",
    "# we then take the intersection from the pdbe codes and write the fasta\n",
    "intersection_results = pdbe_results[pdbe_results[TARGET_COLUMN].isin(intersection)]\n",
    "\n",
    "# We then write the fasta and codes\n",
    "write_fasta(intersection_results, INTERSECTION_PRECLUSTERING_SEQUENCES_PATH)\n",
    "write_pdb_codes(intersection_results, INTERSECTION_CODES_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>target_pdb</th>\n",
       "      <th>sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3byb_B</td>\n",
       "      <td>3byb</td>\n",
       "      <td>KDRPDFCELPADTGPCRVRFPSFYYNPDEKKCLEFIYGGCEGNANN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3auc_A</td>\n",
       "      <td>3auc</td>\n",
       "      <td>RPAFCLEPPYAGPGKARIIRYFYNAAAGAAQTFVYGGVRAKRNNFA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1zr0_D</td>\n",
       "      <td>1zr0</td>\n",
       "      <td>PTGNNAEICLLPLDYGPCRALLLRYYYDRYTQSCRQFLYGGCEGNA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3aui_B</td>\n",
       "      <td>3aui</td>\n",
       "      <td>RPAFCLEPPYAGPGKARIIRYFYNAAAGAAQAFVYGGVRAKRNNFA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3bth_I</td>\n",
       "      <td>3bth</td>\n",
       "      <td>RPDFCLEPPYTGPCHARIIRYFYNAKAGLCQTFVYGGCRAKRNNFK...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target target_pdb                                           sequence\n",
       "0  3byb_B       3byb  KDRPDFCELPADTGPCRVRFPSFYYNPDEKKCLEFIYGGCEGNANN...\n",
       "0  3auc_A       3auc  RPAFCLEPPYAGPGKARIIRYFYNAAAGAAQTFVYGGVRAKRNNFA...\n",
       "0  1zr0_D       1zr0  PTGNNAEICLLPLDYGPCRALLLRYYYDRYTQSCRQFLYGGCEGNA...\n",
       "0  3aui_B       3aui  RPAFCLEPPYAGPGKARIIRYFYNAAAGAAQAFVYGGVRAKRNNFA...\n",
       "0  3bth_I       3bth  RPDFCLEPPYTGPCHARIIRYFYNAKAGLCQTFVYGGCRAKRNNFK..."
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We save a fasta with the names of the codes that are in at least one dataset\n",
    "# to do so, we get the union between the codes and then write the fasta\n",
    "union = pdbe_codes.union(foldseek_codes).union(dali_codes)\n",
    "\n",
    "# we then create a dataframe by creating a dataframe with just three columns: target, target_pdb and sequence\n",
    "# and for each code in the union, we add a row with the code, the first 4 characters of the code and the sequence\n",
    "# to take the sequence, we look first in the pdbe results, then in the foldseek results and lastly in the dali results\n",
    "# if the code is not in any of the results, we throw an error\n",
    "union_results = pd.DataFrame(columns=[TARGET_COLUMN, TARGET_PDB_COLUMN, SEQUENCE_COLUMN])\n",
    "\n",
    "for code in union:\n",
    "    # get the sequence from the pdbe results, foldseek results and dali results\n",
    "    _pdbe_sequence = pdbe_results[pdbe_results[TARGET_COLUMN] == code][SEQUENCE_COLUMN].values\n",
    "    _foldseek_sequence = foldseek_results[foldseek_results[TARGET_COLUMN] == code][SEQUENCE_COLUMN].values\n",
    "    _dali_sequence = dali_results[dali_results[TARGET_COLUMN] == code][SEQUENCE_COLUMN].values\n",
    "    \n",
    "    _pdbe_sequence = _pdbe_sequence[0] if len(_pdbe_sequence) > 0 else None\n",
    "    _foldseek_sequence = _foldseek_sequence[0] if len(_foldseek_sequence) > 0 else None\n",
    "    _dali_sequence = _dali_sequence[0] if len(_dali_sequence) > 0 else None\n",
    "    \n",
    "    # we check that the non null sequences are the same \n",
    "    # if they are not, we throw an error\n",
    "    _all_results = [s for s in [_pdbe_sequence, _foldseek_sequence, _dali_sequence] if s is not None]\n",
    "    if len(_all_results) > 0 and len(set(_all_results)) > 1:\n",
    "        # foldseek only keeps the sequence for the aligned portion of the protein, not the whole sequence so it would be different from the one found on \n",
    "        # the PDB SEQRES file\n",
    "        pass\n",
    "    elif len(_all_results) == 0:\n",
    "        raise ValueError(f\"Sequence for {code} not found in any of the results\")\n",
    "    \n",
    "    sequence = _all_results[0]\n",
    "    \n",
    "    # we then add a row to the dataframe with the code, the first 4 characters of the code and the sequence\n",
    "    union_results = pd.concat([union_results, pd.DataFrame([{\n",
    "        TARGET_COLUMN: code,\n",
    "        TARGET_PDB_COLUMN: code[:4],\n",
    "        SEQUENCE_COLUMN: sequence\n",
    "    }])])\n",
    "\n",
    "union_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the fasta and codes\n",
    "write_fasta(union_results, \"./data/sequences/preclustering-union.txt\")\n",
    "write_pdb_codes(union_results, \"./data/codes/union.txt\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering and Converting to Stockholm format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "CLUSTER_FILE_PATH = \"./data/clusters/union-alfatclust_out.clust\"\n",
    "CLUSTER_EVAL_FILE_PATH = \"./data/clusters/union-alfatclust_out.clust.eval\"\n",
    "CLUSTER_CODES_PATH = \"./data/clusters/union-codes.txt\"\n",
    "\n",
    "ALIGNMENTS_PATH = \"./data/alignment/union.fasta\"\n",
    "ALIGNMENTS_STOCKHOLM_PATH = \"./data/alignment/union.sto\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parses the files produced by alfatclust and returns a dataframe and a dictionary\n",
    "# the dataframe is the eval file and the dictionary maps cluster ids to pdb ids\n",
    "def parse_clust_file(clust_file_path : str, clust_eval_file_path : str) -> tuple[pd.DataFrame, dict[str, list[str]]]:\n",
    "    \n",
    "    # parse the clust file and create a dictionary mapping cluster id to a list of pdb ids\n",
    "    clusters = dict()\n",
    "    with open(clust_file_path, \"r\") as f:\n",
    "        current_cluster = None\n",
    "        for line in f:\n",
    "            if line.startswith(\"#\"):\n",
    "                current_cluster = int(line.split()[1])\n",
    "                clusters[current_cluster] = []\n",
    "            else:\n",
    "                clusters[current_cluster].append(line.strip())\n",
    "\n",
    "    # parse the eval file and create a dataframe from it\n",
    "    with open(clust_eval_file_path, \"r\") as f:\n",
    "        eval_df = pd.read_csv(f)\n",
    "    \n",
    "    # set the index to the Cluster Id column\n",
    "    eval_df.set_index(\"Cluster Id\", inplace=True)\n",
    "        \n",
    "    out_clusters = {}\n",
    "    \n",
    "    # loop over the clusters in the clusters dictionary and:\n",
    "    # if the cluster is in the eval dataframe then we add the id from the \"Center sequence\" column to the out_clusters dictionary\n",
    "    # otherwise, if the cluster has only one pdb id then we add that pdb id to the out_clusters dictionary\n",
    "    # otherwise (if the cluster has more than one pdb id and is not in the eval dataframe) we print a warning\n",
    "    for cluster_id, cluster in clusters.items():\n",
    "        if cluster_id in eval_df.index:\n",
    "            out_clusters[cluster_id] = eval_df.loc[cluster_id][\"Center sequence\"]\n",
    "        elif len(cluster) == 1:\n",
    "            out_clusters[cluster_id] = cluster[0]\n",
    "        else:\n",
    "            print(f\"Warning: cluster {cluster_id} is not in the eval file and has more than one pdb id\")\n",
    "\n",
    "    return eval_df, out_clusters\n",
    "\n",
    "cluster_eval_df, clusters = parse_clust_file(CLUSTER_FILE_PATH, CLUSTER_EVAL_FILE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the values in the cluster dictionary to a file called clusters_codes.txt\n",
    "# replacing the _ with : in the pdb id\n",
    "with open(CLUSTER_CODES_PATH, \"w\") as f:\n",
    "    for cluster_id, pdb_id in clusters.items():\n",
    "        f.write(f\"{pdb_id.replace('_', ':')}\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting the alignments to Stockholm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 24 records\n"
     ]
    }
   ],
   "source": [
    "from Bio import SeqIO\n",
    "\n",
    "\n",
    "# parse the alignments file and create a dictionary mapping the target pdb id to the sequence\n",
    "records = SeqIO.parse(ALIGNMENTS_PATH, \"fasta\")\n",
    "count = SeqIO.write(records, ALIGNMENTS_STOCKHOLM_PATH, \"stockholm\")\n",
    "print(\"Converted %i records\" % count)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
